2025-07-25 10:35:45,931 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.2.0+10018c6
	PyTorch: 2.3.1+cu118
	TorchVision: 0.18.1+cu118
2025-07-25 10:35:45,931 INFO: 
  name: MambaIR_RealDN
  model_type: ImageCleanModel
  scale: 1
  num_gpu: 8
  manual_seed: 100
  datasets:[
    train:[
      name: TrainSet
      type: Dataset_PairedImage
      dataroot_gt: /data/lgl/datasets/LowLight/LOL-v1/our485/high
      dataroot_lq: /data/lgl/datasets/LowLight/LOL-v1/our485/low
      geometric_augs: True
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      use_shuffle: True
      num_worker_per_gpu: 0
      batch_size_per_gpu: 1
      mini_batch_sizes: [8, 5, 4, 2, 1, 1]
      iters: [92000, 64000, 48000, 36000, 36000, 24000]
      gt_size: 384
      gt_sizes: [128, 160, 192, 256, 320, 384]
      dataset_enlarge_ratio: 100
      prefetch_mode: None
      phase: train
      scale: 1
    ]
    val:[
      name: ValSet
      type: Dataset_PairedImage
      dataroot_gt: /data/lgl/datasets/LowLight/LOL-v1/eval15/high
      dataroot_lq: /data/lgl/datasets/LowLight/LOL-v1/eval15/low
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: MambaIRUNet
    inp_channels: 3
    out_channels: 3
    dim: 48
    num_blocks: [4, 6, 6, 8]
    num_refinement_blocks: 4
    mlp_ratio: 1.5
    bias: False
    dual_pixel_task: False
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: experiments/MambaIR_RealDN/training_states/196000.state
    root: /data/lgl/codes/MambaIR/realDenoising
    experiments_root: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN
    models: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models
    training_states: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/training_states
    log: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN
    visualization: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/visualization
  ]
  train:[
    total_iter: 300000
    warmup_iter: -1
    use_grad_clip: True
    scheduler:[
      type: CosineAnnealingRestartCyclicLR
      periods: [92000, 208000]
      restart_weights: [1, 1]
      eta_mins: [0.0003, 1e-06]
    ]
    mixing_augs:[
      mixup: True
      mixup_beta: 1.2
      use_identity: True
    ]
    optim_g:[
      type: AdamW
      lr: 0.0003
      weight_decay: 0.0001
      betas: [0.9, 0.999]
    ]
    pixel_opt:[
      type: L1Loss
      loss_weight: 1
      reduction: mean
    ]
  ]
  val:[
    window_size: 8
    val_freq: 4000.0
    save_img: False
    rgb2bgr: True
    use_image: False
    max_minibatch: 8
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 1000
    save_checkpoint_freq: 4000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  is_train: True
  dist: True
  rank: 0
  world_size: 4

2025-07-25 10:35:46,193 INFO: Dataset Dataset_PairedImage - TrainSet is created.
2025-07-25 10:35:46,193 INFO: Training statistics:
	Number of train images: 485
	Dataset enlarge ratio: 100
	Batch size per gpu: 1
	World size (gpu number): 4
	Require iter number per epoch: 12125
	Total epochs: 25; iters: 300000.
2025-07-25 10:35:46,194 INFO: Dataset Dataset_PairedImage - ValSet is created.
2025-07-25 10:35:46,194 INFO: Number of val images/folders in ValSet: 15
2025-07-25 10:35:46,194 INFO: Set pretrain_network_g to /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models/net_g_196000.pth
2025-07-25 10:35:46,955 INFO: Network: DistributedDataParallel - MambaIRUNet, with parameters: 26,779,480
2025-07-25 10:35:46,955 INFO: MambaIRUNet(
  (patch_embed): OverlapPatchEmbed(
    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (encoder_level1): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=48, out_features=144, bias=False)
        (conv2d): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)
        (act): SiLU()
        (out_norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=72, out_features=48, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down1_2): Downsample(
    (body): Sequential(
      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level2): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down2_3): Downsample(
    (body): Sequential(
      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level3): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=192, out_features=576, bias=False)
        (conv2d): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        (act): SiLU()
        (out_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=288, out_features=192, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(192, 6, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(6, 192, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down3_4): Downsample(
    (body): Sequential(
      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (latent): ModuleList(
    (0-7): 8 x VSSBlock(
      (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=384, out_features=1152, bias=False)
        (conv2d): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (act): SiLU()
        (out_norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=576, out_features=384, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(12, 384, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up4_3): Upsample(
    (body): Sequential(
      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level3): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=192, out_features=576, bias=False)
        (conv2d): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        (act): SiLU()
        (out_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=288, out_features=192, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(192, 6, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(6, 192, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up3_2): Upsample(
    (body): Sequential(
      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level2): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up2_1): Upsample(
    (body): Sequential(
      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (decoder_level1): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (refinement): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)
2025-07-25 10:35:46,955 INFO: Loading MambaIRUNet model from /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models/net_g_196000.pth.
2025-07-25 10:35:47,207 INFO: Model [ImageCleanModel] is created.
2025-07-25 10:35:47,229 INFO: Resuming training from epoch: 16, iter: 196000.
2025-07-25 10:35:47,229 INFO: Start training from epoch: 16, iter: 196000
2025-07-25 10:35:47,256 INFO: 
 Updating Patch_Size to 192 and Batch_Size to 16 

2025-07-25 10:45:01,794 INFO: [Mamba..][epoch: 16, iter: 197,000, lr:(1.482e-04,)] [eta: 15:51:02, time (data): 0.555 (0.020)] l_pix: 2.0901e-02 
2025-07-25 10:54:14,646 INFO: [Mamba..][epoch: 16, iter: 198,000, lr:(1.460e-04,)] [eta: 15:40:49, time (data): 0.548 (0.019)] l_pix: 1.9858e-02 
2025-07-25 11:03:29,010 INFO: [Mamba..][epoch: 16, iter: 199,000, lr:(1.437e-04,)] [eta: 15:32:07, time (data): 0.548 (0.017)] l_pix: 1.7282e-02 
2025-07-25 11:12:41,517 INFO: [Mamba..][epoch: 16, iter: 200,000, lr:(1.415e-04,)] [eta: 15:22:22, time (data): 0.547 (0.015)] l_pix: 3.3962e-02 
2025-07-25 11:12:41,517 INFO: Saving models and training states.
2025-07-25 11:12:54,663 INFO: Validation ValSet,		 # psnr: 23.0479
2025-07-25 11:22:07,009 INFO: [Mamba..][epoch: 16, iter: 201,000, lr:(1.392e-04,)] [eta: 15:17:08, time (data): 0.556 (0.016)] l_pix: 1.5821e-02 
2025-07-25 11:31:19,054 INFO: [Mamba..][epoch: 16, iter: 202,000, lr:(1.370e-04,)] [eta: 15:06:50, time (data): 0.554 (0.018)] l_pix: 1.6021e-02 
2025-07-25 11:40:31,592 INFO: [Mamba..][epoch: 16, iter: 203,000, lr:(1.347e-04,)] [eta: 14:56:57, time (data): 0.550 (0.017)] l_pix: 2.2096e-02 
2025-07-25 11:49:44,157 INFO: [Mamba..][epoch: 16, iter: 204,000, lr:(1.325e-04,)] [eta: 14:47:15, time (data): 0.548 (0.018)] l_pix: 2.3966e-02 
2025-07-25 11:49:44,158 INFO: Saving models and training states.
2025-07-25 11:49:56,854 INFO: Validation ValSet,		 # psnr: 23.1423
2025-07-25 11:49:56,869 INFO: 
 Updating Patch_Size to 256 and Batch_Size to 8 

2025-07-25 12:04:17,859 INFO: [Mamba..][epoch: 16, iter: 205,000, lr:(1.302e-04,)] [eta: 15:34:09, time (data): 0.852 (0.017)] l_pix: 1.3635e-02 
2025-07-25 12:18:37,837 INFO: [Mamba..][epoch: 16, iter: 206,000, lr:(1.280e-04,)] [eta: 16:06:37, time (data): 0.855 (0.018)] l_pix: 2.3029e-02 
2025-07-25 12:32:58,055 INFO: [Mamba..][epoch: 16, iter: 207,000, lr:(1.258e-04,)] [eta: 16:30:36, time (data): 0.864 (0.015)] l_pix: 2.1626e-02 
2025-07-25 12:47:18,156 INFO: [Mamba..][epoch: 16, iter: 208,000, lr:(1.236e-04,)] [eta: 16:48:11, time (data): 0.854 (0.018)] l_pix: 1.8864e-02 
2025-07-25 12:47:18,157 INFO: Saving models and training states.
2025-07-25 12:47:31,114 INFO: Validation ValSet,		 # psnr: 23.3608
2025-07-25 13:01:51,219 INFO: [Mamba..][epoch: 17, iter: 209,000, lr:(1.213e-04,)] [eta: 17:02:22, time (data): 0.860 (0.018)] l_pix: 3.4274e-02 
2025-07-25 13:16:10,890 INFO: [Mamba..][epoch: 17, iter: 210,000, lr:(1.191e-04,)] [eta: 17:11:01, time (data): 0.854 (0.015)] l_pix: 2.2434e-02 
2025-07-25 13:30:31,402 INFO: [Mamba..][epoch: 17, iter: 211,000, lr:(1.169e-04,)] [eta: 17:16:41, time (data): 0.862 (0.017)] l_pix: 1.7123e-02 
2025-07-25 13:44:51,331 INFO: [Mamba..][epoch: 17, iter: 212,000, lr:(1.147e-04,)] [eta: 17:19:47, time (data): 0.844 (0.019)] l_pix: 2.1132e-02 
2025-07-25 13:44:51,332 INFO: Saving models and training states.
2025-07-25 13:45:04,112 INFO: Validation ValSet,		 # psnr: 23.2736
2025-07-25 13:59:23,986 INFO: [Mamba..][epoch: 17, iter: 213,000, lr:(1.125e-04,)] [eta: 17:21:56, time (data): 0.859 (0.017)] l_pix: 1.9153e-02 
2025-07-25 14:13:43,631 INFO: [Mamba..][epoch: 17, iter: 214,000, lr:(1.104e-04,)] [eta: 17:21:11, time (data): 0.856 (0.017)] l_pix: 1.1191e-02 
2025-07-25 14:28:03,321 INFO: [Mamba..][epoch: 17, iter: 215,000, lr:(1.082e-04,)] [eta: 17:19:01, time (data): 0.857 (0.018)] l_pix: 1.7195e-02 
2025-07-25 14:42:23,328 INFO: [Mamba..][epoch: 17, iter: 216,000, lr:(1.060e-04,)] [eta: 17:15:39, time (data): 0.855 (0.019)] l_pix: 1.6267e-02 
2025-07-25 14:42:23,329 INFO: Saving models and training states.
2025-07-25 14:42:36,135 INFO: Validation ValSet,		 # psnr: 23.1072
2025-07-25 14:56:57,066 INFO: [Mamba..][epoch: 17, iter: 217,000, lr:(1.039e-04,)] [eta: 17:12:09, time (data): 0.860 (0.016)] l_pix: 2.6631e-02 
2025-07-25 15:11:17,807 INFO: [Mamba..][epoch: 17, iter: 218,000, lr:(1.017e-04,)] [eta: 17:06:50, time (data): 0.867 (0.016)] l_pix: 1.8034e-02 
2025-07-25 15:25:39,053 INFO: [Mamba..][epoch: 17, iter: 219,000, lr:(9.961e-05,)] [eta: 17:00:46, time (data): 0.862 (0.018)] l_pix: 1.3106e-02 
2025-07-25 15:39:59,799 INFO: [Mamba..][epoch: 17, iter: 220,000, lr:(9.749e-05,)] [eta: 16:53:58, time (data): 0.863 (0.018)] l_pix: 1.7132e-02 
2025-07-25 15:39:59,799 INFO: Saving models and training states.
2025-07-25 15:40:12,728 INFO: Validation ValSet,		 # psnr: 23.5779
2025-07-25 15:54:33,614 INFO: [Mamba..][epoch: 18, iter: 221,000, lr:(9.538e-05,)] [eta: 16:47:16, time (data): 0.862 (0.018)] l_pix: 1.7146e-02 
2025-07-25 16:08:54,066 INFO: [Mamba..][epoch: 18, iter: 222,000, lr:(9.329e-05,)] [eta: 16:39:17, time (data): 0.860 (0.015)] l_pix: 2.1229e-02 
2025-07-25 16:23:14,781 INFO: [Mamba..][epoch: 18, iter: 223,000, lr:(9.121e-05,)] [eta: 16:30:51, time (data): 0.861 (0.018)] l_pix: 2.9632e-02 
2025-07-25 16:37:35,033 INFO: [Mamba..][epoch: 18, iter: 224,000, lr:(8.915e-05,)] [eta: 16:21:58, time (data): 0.863 (0.017)] l_pix: 1.1609e-02 
2025-07-25 16:37:35,034 INFO: Saving models and training states.
2025-07-25 16:37:47,802 INFO: Validation ValSet,		 # psnr: 23.6326
2025-07-25 16:52:08,006 INFO: [Mamba..][epoch: 18, iter: 225,000, lr:(8.709e-05,)] [eta: 16:13:15, time (data): 0.859 (0.017)] l_pix: 1.5023e-02 
2025-07-25 17:06:28,686 INFO: [Mamba..][epoch: 18, iter: 226,000, lr:(8.506e-05,)] [eta: 16:03:39, time (data): 0.861 (0.018)] l_pix: 2.0824e-02 
2025-07-25 17:20:49,730 INFO: [Mamba..][epoch: 18, iter: 227,000, lr:(8.303e-05,)] [eta: 15:53:45, time (data): 0.861 (0.017)] l_pix: 1.7386e-02 
2025-07-25 17:35:10,652 INFO: [Mamba..][epoch: 18, iter: 228,000, lr:(8.103e-05,)] [eta: 15:43:35, time (data): 0.860 (0.019)] l_pix: 1.9840e-02 
2025-07-25 17:35:10,653 INFO: Saving models and training states.
2025-07-25 17:35:23,423 INFO: Validation ValSet,		 # psnr: 23.6476
2025-07-25 17:49:44,461 INFO: [Mamba..][epoch: 18, iter: 229,000, lr:(7.903e-05,)] [eta: 15:33:37, time (data): 0.865 (0.019)] l_pix: 1.6127e-02 
2025-07-25 18:04:05,370 INFO: [Mamba..][epoch: 18, iter: 230,000, lr:(7.706e-05,)] [eta: 15:22:56, time (data): 0.866 (0.019)] l_pix: 2.2783e-02 
2025-07-25 18:18:26,658 INFO: [Mamba..][epoch: 18, iter: 231,000, lr:(7.510e-05,)] [eta: 15:12:03, time (data): 0.863 (0.018)] l_pix: 1.6338e-02 
2025-07-25 18:32:47,558 INFO: [Mamba..][epoch: 18, iter: 232,000, lr:(7.316e-05,)] [eta: 15:00:58, time (data): 0.859 (0.018)] l_pix: 1.9701e-02 
2025-07-25 18:32:47,558 INFO: Saving models and training states.
2025-07-25 18:33:00,444 INFO: Validation ValSet,		 # psnr: 23.9575
2025-07-25 18:47:21,113 INFO: [Mamba..][epoch: 19, iter: 233,000, lr:(7.124e-05,)] [eta: 14:50:05, time (data): 0.859 (0.018)] l_pix: 2.8921e-02 
2025-07-25 19:01:41,977 INFO: [Mamba..][epoch: 19, iter: 234,000, lr:(6.933e-05,)] [eta: 14:38:39, time (data): 0.855 (0.015)] l_pix: 2.0880e-02 
2025-07-25 19:16:02,531 INFO: [Mamba..][epoch: 19, iter: 235,000, lr:(6.744e-05,)] [eta: 14:27:03, time (data): 0.857 (0.017)] l_pix: 2.0811e-02 
2025-07-25 19:30:23,067 INFO: [Mamba..][epoch: 19, iter: 236,000, lr:(6.558e-05,)] [eta: 14:15:19, time (data): 0.862 (0.019)] l_pix: 2.6066e-02 
2025-07-25 19:30:23,068 INFO: Saving models and training states.
2025-07-25 19:30:35,952 INFO: Validation ValSet,		 # psnr: 23.8038
2025-07-25 19:44:56,546 INFO: [Mamba..][epoch: 19, iter: 237,000, lr:(6.373e-05,)] [eta: 14:03:47, time (data): 0.858 (0.018)] l_pix: 2.0823e-02 
2025-07-25 19:59:17,208 INFO: [Mamba..][epoch: 19, iter: 238,000, lr:(6.190e-05,)] [eta: 13:51:47, time (data): 0.858 (0.018)] l_pix: 1.7270e-02 
2025-07-25 20:13:37,932 INFO: [Mamba..][epoch: 19, iter: 239,000, lr:(6.009e-05,)] [eta: 13:39:42, time (data): 0.852 (0.018)] l_pix: 1.5654e-02 
2025-07-25 20:27:59,082 INFO: [Mamba..][epoch: 19, iter: 240,000, lr:(5.830e-05,)] [eta: 13:27:30, time (data): 0.864 (0.017)] l_pix: 2.2544e-02 
2025-07-25 20:27:59,083 INFO: Saving models and training states.
2025-07-25 20:28:11,888 INFO: Validation ValSet,		 # psnr: 23.5065
2025-07-25 20:28:11,908 INFO: 
 Updating Patch_Size to 320 and Batch_Size to 4 

2025-07-25 20:51:35,937 INFO: [Mamba..][epoch: 19, iter: 241,000, lr:(5.654e-05,)] [eta: 13:27:21, time (data): 1.404 (0.017)] l_pix: 2.5260e-02 
2025-07-25 21:14:57,950 INFO: [Mamba..][epoch: 19, iter: 242,000, lr:(5.479e-05,)] [eta: 13:25:53, time (data): 1.403 (0.018)] l_pix: 1.9241e-02 
2025-07-25 21:38:20,572 INFO: [Mamba..][epoch: 19, iter: 243,000, lr:(5.307e-05,)] [eta: 13:23:29, time (data): 1.397 (0.015)] l_pix: 1.0439e-02 
2025-07-25 22:01:42,980 INFO: [Mamba..][epoch: 19, iter: 244,000, lr:(5.136e-05,)] [eta: 13:20:13, time (data): 1.404 (0.018)] l_pix: 1.5880e-02 
2025-07-25 22:01:42,980 INFO: Saving models and training states.
2025-07-25 22:01:55,856 INFO: Validation ValSet,		 # psnr: 24.2014
2025-07-25 22:25:18,498 INFO: [Mamba..][epoch: 20, iter: 245,000, lr:(4.969e-05,)] [eta: 13:16:22, time (data): 1.408 (0.019)] l_pix: 1.4513e-02 
2025-07-25 22:48:40,903 INFO: [Mamba..][epoch: 20, iter: 246,000, lr:(4.803e-05,)] [eta: 13:11:29, time (data): 1.404 (0.018)] l_pix: 1.3991e-02 
2025-07-25 23:12:03,282 INFO: [Mamba..][epoch: 20, iter: 247,000, lr:(4.640e-05,)] [eta: 13:05:53, time (data): 1.405 (0.015)] l_pix: 1.4717e-02 
2025-07-25 23:35:26,000 INFO: [Mamba..][epoch: 20, iter: 248,000, lr:(4.479e-05,)] [eta: 12:59:36, time (data): 1.397 (0.015)] l_pix: 1.1616e-02 
2025-07-25 23:35:26,000 INFO: Saving models and training states.
2025-07-25 23:35:38,937 INFO: Validation ValSet,		 # psnr: 24.2046
2025-07-25 23:59:01,606 INFO: [Mamba..][epoch: 20, iter: 249,000, lr:(4.320e-05,)] [eta: 12:52:53, time (data): 1.395 (0.016)] l_pix: 1.4585e-02 
2025-07-26 00:22:23,950 INFO: [Mamba..][epoch: 20, iter: 250,000, lr:(4.164e-05,)] [eta: 12:45:21, time (data): 1.400 (0.018)] l_pix: 1.3976e-02 
2025-07-26 00:45:46,062 INFO: [Mamba..][epoch: 20, iter: 251,000, lr:(4.011e-05,)] [eta: 12:37:13, time (data): 1.400 (0.018)] l_pix: 1.5313e-02 
2025-07-26 01:09:08,123 INFO: [Mamba..][epoch: 20, iter: 252,000, lr:(3.860e-05,)] [eta: 12:28:33, time (data): 1.403 (0.018)] l_pix: 2.2997e-02 
2025-07-26 01:09:08,123 INFO: Saving models and training states.
2025-07-26 01:09:21,147 INFO: Validation ValSet,		 # psnr: 24.0004
2025-07-26 01:32:43,063 INFO: [Mamba..][epoch: 20, iter: 253,000, lr:(3.711e-05,)] [eta: 12:19:32, time (data): 1.405 (0.015)] l_pix: 1.4829e-02 
2025-07-26 01:56:05,356 INFO: [Mamba..][epoch: 20, iter: 254,000, lr:(3.566e-05,)] [eta: 12:09:51, time (data): 1.398 (0.016)] l_pix: 1.9136e-02 
2025-07-26 02:19:27,442 INFO: [Mamba..][epoch: 20, iter: 255,000, lr:(3.422e-05,)] [eta: 11:59:43, time (data): 1.405 (0.018)] l_pix: 1.5773e-02 
2025-07-26 02:42:49,713 INFO: [Mamba..][epoch: 20, iter: 256,000, lr:(3.282e-05,)] [eta: 11:49:08, time (data): 1.399 (0.018)] l_pix: 1.3098e-02 
2025-07-26 02:42:49,714 INFO: Saving models and training states.
2025-07-26 02:43:02,747 INFO: Validation ValSet,		 # psnr: 23.9137
2025-07-26 03:06:25,559 INFO: [Mamba..][epoch: 21, iter: 257,000, lr:(3.144e-05,)] [eta: 11:38:17, time (data): 1.404 (0.017)] l_pix: 1.8708e-02 
2025-07-26 03:29:48,290 INFO: [Mamba..][epoch: 21, iter: 258,000, lr:(3.009e-05,)] [eta: 11:26:53, time (data): 1.403 (0.018)] l_pix: 1.3081e-02 
2025-07-26 03:53:10,832 INFO: [Mamba..][epoch: 21, iter: 259,000, lr:(2.876e-05,)] [eta: 11:15:06, time (data): 1.404 (0.015)] l_pix: 1.6691e-02 
2025-07-26 04:16:33,236 INFO: [Mamba..][epoch: 21, iter: 260,000, lr:(2.747e-05,)] [eta: 11:02:57, time (data): 1.402 (0.016)] l_pix: 1.4654e-02 
2025-07-26 04:16:33,236 INFO: Saving models and training states.
2025-07-26 04:16:46,134 INFO: Validation ValSet,		 # psnr: 24.2632
2025-07-26 04:40:08,586 INFO: [Mamba..][epoch: 21, iter: 261,000, lr:(2.620e-05,)] [eta: 10:50:35, time (data): 1.404 (0.018)] l_pix: 1.3245e-02 
2025-07-26 05:03:30,516 INFO: [Mamba..][epoch: 21, iter: 262,000, lr:(2.496e-05,)] [eta: 10:37:45, time (data): 1.404 (0.016)] l_pix: 1.7353e-02 
2025-07-26 05:26:52,548 INFO: [Mamba..][epoch: 21, iter: 263,000, lr:(2.374e-05,)] [eta: 10:24:36, time (data): 1.398 (0.015)] l_pix: 1.2563e-02 
2025-07-26 05:50:13,869 INFO: [Mamba..][epoch: 21, iter: 264,000, lr:(2.256e-05,)] [eta: 10:11:09, time (data): 1.406 (0.015)] l_pix: 1.5811e-02 
2025-07-26 05:50:13,870 INFO: Saving models and training states.
2025-07-26 05:50:26,736 INFO: Validation ValSet,		 # psnr: 24.2369
2025-07-26 06:13:49,651 INFO: [Mamba..][epoch: 21, iter: 265,000, lr:(2.141e-05,)] [eta: 9:57:31, time (data): 1.400 (0.016)] l_pix: 1.2689e-02 
2025-07-26 06:37:12,698 INFO: [Mamba..][epoch: 21, iter: 266,000, lr:(2.028e-05,)] [eta: 9:43:31, time (data): 1.402 (0.018)] l_pix: 1.2315e-02 
2025-07-26 07:00:35,700 INFO: [Mamba..][epoch: 21, iter: 267,000, lr:(1.919e-05,)] [eta: 9:29:15, time (data): 1.397 (0.016)] l_pix: 2.3569e-02 
2025-07-26 07:23:59,045 INFO: [Mamba..][epoch: 21, iter: 268,000, lr:(1.813e-05,)] [eta: 9:14:43, time (data): 1.395 (0.016)] l_pix: 2.2035e-02 
2025-07-26 07:23:59,046 INFO: Saving models and training states.
2025-07-26 07:24:11,924 INFO: Validation ValSet,		 # psnr: 24.3450
2025-07-26 07:47:34,539 INFO: [Mamba..][epoch: 22, iter: 269,000, lr:(1.709e-05,)] [eta: 9:00:02, time (data): 1.401 (0.018)] l_pix: 1.7439e-02 
2025-07-26 08:10:56,811 INFO: [Mamba..][epoch: 22, iter: 270,000, lr:(1.609e-05,)] [eta: 8:45:02, time (data): 1.404 (0.018)] l_pix: 1.3400e-02 
2025-07-26 08:34:18,691 INFO: [Mamba..][epoch: 22, iter: 271,000, lr:(1.511e-05,)] [eta: 8:29:48, time (data): 1.407 (0.018)] l_pix: 1.9914e-02 
2025-07-26 08:57:41,315 INFO: [Mamba..][epoch: 22, iter: 272,000, lr:(1.417e-05,)] [eta: 8:14:21, time (data): 1.405 (0.015)] l_pix: 1.6372e-02 
2025-07-26 08:57:41,315 INFO: Saving models and training states.
2025-07-26 08:57:54,363 INFO: Validation ValSet,		 # psnr: 24.2831
2025-07-26 09:21:17,260 INFO: [Mamba..][epoch: 22, iter: 273,000, lr:(1.326e-05,)] [eta: 7:58:47, time (data): 1.397 (0.018)] l_pix: 1.5002e-02 
2025-07-26 09:44:39,970 INFO: [Mamba..][epoch: 22, iter: 274,000, lr:(1.238e-05,)] [eta: 7:42:56, time (data): 1.408 (0.015)] l_pix: 1.7531e-02 
2025-07-26 10:08:03,481 INFO: [Mamba..][epoch: 22, iter: 275,000, lr:(1.153e-05,)] [eta: 7:26:53, time (data): 1.403 (0.018)] l_pix: 1.5303e-02 
2025-07-26 10:31:25,913 INFO: [Mamba..][epoch: 22, iter: 276,000, lr:(1.072e-05,)] [eta: 7:10:40, time (data): 1.401 (0.015)] l_pix: 1.4870e-02 
2025-07-26 10:31:25,913 INFO: Saving models and training states.
