2025-07-26 11:20:47,687 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.2.0+10018c6
	PyTorch: 2.3.1+cu118
	TorchVision: 0.18.1+cu118
2025-07-26 11:20:47,687 INFO: 
  name: MambaIR_RealDN
  model_type: ImageCleanModel
  scale: 1
  num_gpu: 8
  manual_seed: 100
  datasets:[
    train:[
      name: TrainSet
      type: Dataset_PairedImage
      dataroot_gt: /data/lgl/datasets/LowLight/LOL-v1/our485/high
      dataroot_lq: /data/lgl/datasets/LowLight/LOL-v1/our485/low
      geometric_augs: True
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      use_shuffle: True
      num_worker_per_gpu: 0
      batch_size_per_gpu: 1
      mini_batch_sizes: [8, 5, 4, 2, 1, 1]
      iters: [92000, 64000, 48000, 36000, 36000, 24000]
      gt_size: 384
      gt_sizes: [128, 160, 192, 256, 320, 320]
      dataset_enlarge_ratio: 100
      prefetch_mode: None
      phase: train
      scale: 1
    ]
    val:[
      name: ValSet
      type: Dataset_PairedImage
      dataroot_gt: /data/lgl/datasets/LowLight/LOL-v1/eval15/high
      dataroot_lq: /data/lgl/datasets/LowLight/LOL-v1/eval15/low
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: MambaIRUNet
    inp_channels: 3
    out_channels: 3
    dim: 48
    num_blocks: [4, 6, 6, 8]
    num_refinement_blocks: 4
    mlp_ratio: 1.5
    bias: False
    dual_pixel_task: False
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: experiments/MambaIR_RealDN/training_states/276000.state
    root: /data/lgl/codes/MambaIR/realDenoising
    experiments_root: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN
    models: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models
    training_states: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/training_states
    log: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN
    visualization: /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/visualization
  ]
  train:[
    total_iter: 300000
    warmup_iter: -1
    use_grad_clip: True
    scheduler:[
      type: CosineAnnealingRestartCyclicLR
      periods: [92000, 208000]
      restart_weights: [1, 1]
      eta_mins: [0.0003, 1e-06]
    ]
    mixing_augs:[
      mixup: True
      mixup_beta: 1.2
      use_identity: True
    ]
    optim_g:[
      type: AdamW
      lr: 0.0003
      weight_decay: 0.0001
      betas: [0.9, 0.999]
    ]
    pixel_opt:[
      type: L1Loss
      loss_weight: 1
      reduction: mean
    ]
  ]
  val:[
    window_size: 8
    val_freq: 4000.0
    save_img: False
    rgb2bgr: True
    use_image: False
    max_minibatch: 8
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 1000
    save_checkpoint_freq: 4000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  is_train: True
  dist: True
  rank: 0
  world_size: 4

2025-07-26 11:20:47,822 INFO: Dataset Dataset_PairedImage - TrainSet is created.
2025-07-26 11:20:47,822 INFO: Training statistics:
	Number of train images: 485
	Dataset enlarge ratio: 100
	Batch size per gpu: 1
	World size (gpu number): 4
	Require iter number per epoch: 12125
	Total epochs: 25; iters: 300000.
2025-07-26 11:20:47,823 INFO: Dataset Dataset_PairedImage - ValSet is created.
2025-07-26 11:20:47,823 INFO: Number of val images/folders in ValSet: 15
2025-07-26 11:20:47,823 INFO: Set pretrain_network_g to /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models/net_g_276000.pth
2025-07-26 11:20:48,592 INFO: Network: DistributedDataParallel - MambaIRUNet, with parameters: 26,779,480
2025-07-26 11:20:48,592 INFO: MambaIRUNet(
  (patch_embed): OverlapPatchEmbed(
    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (encoder_level1): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=48, out_features=144, bias=False)
        (conv2d): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72)
        (act): SiLU()
        (out_norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=72, out_features=48, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down1_2): Downsample(
    (body): Sequential(
      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level2): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down2_3): Downsample(
    (body): Sequential(
      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level3): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=192, out_features=576, bias=False)
        (conv2d): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        (act): SiLU()
        (out_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=288, out_features=192, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(192, 6, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(6, 192, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
  )
  (down3_4): Downsample(
    (body): Sequential(
      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (latent): ModuleList(
    (0-7): 8 x VSSBlock(
      (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=384, out_features=1152, bias=False)
        (conv2d): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (act): SiLU()
        (out_norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=576, out_features=384, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(12, 384, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up4_3): Upsample(
    (body): Sequential(
      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level3): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=192, out_features=576, bias=False)
        (conv2d): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        (act): SiLU()
        (out_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=288, out_features=192, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(192, 6, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(6, 192, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up3_2): Upsample(
    (body): Sequential(
      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level2): ModuleList(
    (0-5): 6 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (up2_1): Upsample(
    (body): Sequential(
      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (decoder_level1): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (refinement): ModuleList(
    (0-3): 4 x VSSBlock(
      (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (self_attention): SS2D(
        (in_proj): Linear(in_features=96, out_features=288, bias=False)
        (conv2d): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (act): SiLU()
        (out_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
        (out_proj): Linear(in_features=144, out_features=96, bias=False)
      )
      (drop_path): DropPath(drop_prob=0.000)
      (conv_blk): CAB(
        (cab): Sequential(
          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ChannelAttention(
            (attention): Sequential(
              (0): AdaptiveAvgPool2d(output_size=1)
              (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))
              (2): ReLU(inplace=True)
              (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))
              (4): Sigmoid()
            )
          )
        )
      )
      (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
  )
  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)
2025-07-26 11:20:48,592 INFO: Loading MambaIRUNet model from /data/lgl/codes/MambaIR/realDenoising/experiments/MambaIR_RealDN/models/net_g_276000.pth.
2025-07-26 11:20:48,859 INFO: Model [ImageCleanModel] is created.
2025-07-26 11:20:48,881 INFO: Resuming training from epoch: 22, iter: 276000.
2025-07-26 11:20:48,881 INFO: Start training from epoch: 22, iter: 276000
2025-07-26 11:20:48,912 INFO: 
 Updating Patch_Size to 320 and Batch_Size to 4 

2025-07-26 11:44:11,252 INFO: [Mamba..][epoch: 22, iter: 277,000, lr:(9.931e-06,)] [eta: 8:57:00, time (data): 1.402 (0.022)] l_pix: 2.1710e-02 
2025-07-26 12:07:37,215 INFO: [Mamba..][epoch: 22, iter: 278,000, lr:(9.178e-06,)] [eta: 8:34:34, time (data): 1.392 (0.020)] l_pix: 1.3849e-02 
2025-07-26 12:30:54,143 INFO: [Mamba..][epoch: 22, iter: 279,000, lr:(8.458e-06,)] [eta: 8:10:25, time (data): 1.396 (0.016)] l_pix: 1.4095e-02 
2025-07-26 12:54:12,291 INFO: [Mamba..][epoch: 22, iter: 280,000, lr:(7.770e-06,)] [eta: 7:46:48, time (data): 1.392 (0.016)] l_pix: 1.7632e-02 
2025-07-26 12:54:12,292 INFO: Saving models and training states.
2025-07-26 12:54:25,719 INFO: Validation ValSet,		 # psnr: 24.2728
2025-07-26 13:17:46,433 INFO: [Mamba..][epoch: 22, iter: 281,000, lr:(7.114e-06,)] [eta: 7:24:19, time (data): 1.395 (0.018)] l_pix: 1.4219e-02 
2025-07-26 13:41:04,856 INFO: [Mamba..][epoch: 22, iter: 282,000, lr:(6.492e-06,)] [eta: 7:00:42, time (data): 1.390 (0.019)] l_pix: 1.4416e-02 
2025-07-26 14:04:22,101 INFO: [Mamba..][epoch: 22, iter: 283,000, lr:(5.902e-06,)] [eta: 6:37:07, time (data): 1.396 (0.018)] l_pix: 1.9793e-02 
2025-07-26 14:27:46,862 INFO: [Mamba..][epoch: 22, iter: 284,000, lr:(5.345e-06,)] [eta: 6:13:51, time (data): 1.399 (0.019)] l_pix: 1.9954e-02 
2025-07-26 14:27:46,863 INFO: Saving models and training states.
2025-07-26 14:27:59,754 INFO: Validation ValSet,		 # psnr: 24.2560
2025-07-26 14:51:19,228 INFO: [Mamba..][epoch: 22, iter: 285,000, lr:(4.821e-06,)] [eta: 5:50:46, time (data): 1.395 (0.018)] l_pix: 1.4691e-02 
2025-07-26 15:14:40,902 INFO: [Mamba..][epoch: 22, iter: 286,000, lr:(4.330e-06,)] [eta: 5:27:21, time (data): 1.400 (0.020)] l_pix: 1.8145e-02 
2025-07-26 15:38:00,741 INFO: [Mamba..][epoch: 22, iter: 287,000, lr:(3.873e-06,)] [eta: 5:03:54, time (data): 1.400 (0.015)] l_pix: 1.4837e-02 
2025-07-26 16:01:20,890 INFO: [Mamba..][epoch: 22, iter: 288,000, lr:(3.449e-06,)] [eta: 4:40:29, time (data): 1.401 (0.020)] l_pix: 1.4981e-02 
2025-07-26 16:01:20,891 INFO: Saving models and training states.
2025-07-26 16:01:33,940 INFO: Validation ValSet,		 # psnr: 24.2871
2025-07-26 16:24:54,219 INFO: [Mamba..][epoch: 23, iter: 289,000, lr:(3.059e-06,)] [eta: 4:17:15, time (data): 1.398 (0.018)] l_pix: 1.2330e-02 
2025-07-26 16:48:21,704 INFO: [Mamba..][epoch: 23, iter: 290,000, lr:(2.702e-06,)] [eta: 3:53:55, time (data): 1.398 (0.016)] l_pix: 1.5881e-02 
2025-07-26 17:11:40,840 INFO: [Mamba..][epoch: 23, iter: 291,000, lr:(2.379e-06,)] [eta: 3:30:28, time (data): 1.394 (0.017)] l_pix: 1.7673e-02 
2025-07-26 17:34:59,498 INFO: [Mamba..][epoch: 23, iter: 292,000, lr:(2.090e-06,)] [eta: 3:07:03, time (data): 1.394 (0.019)] l_pix: 1.4353e-02 
2025-07-26 17:34:59,498 INFO: Saving models and training states.
2025-07-26 17:35:12,426 INFO: Validation ValSet,		 # psnr: 24.3115
2025-07-26 17:58:29,532 INFO: [Mamba..][epoch: 23, iter: 293,000, lr:(1.835e-06,)] [eta: 2:43:42, time (data): 1.398 (0.017)] l_pix: 1.1280e-02 
2025-07-26 18:21:46,583 INFO: [Mamba..][epoch: 23, iter: 294,000, lr:(1.614e-06,)] [eta: 2:20:17, time (data): 1.389 (0.019)] l_pix: 1.3627e-02 
2025-07-26 18:45:03,195 INFO: [Mamba..][epoch: 23, iter: 295,000, lr:(1.426e-06,)] [eta: 1:56:52, time (data): 1.403 (0.019)] l_pix: 1.0531e-02 
2025-07-26 19:08:22,727 INFO: [Mamba..][epoch: 23, iter: 296,000, lr:(1.273e-06,)] [eta: 1:33:29, time (data): 1.394 (0.017)] l_pix: 1.7706e-02 
2025-07-26 19:08:22,728 INFO: Saving models and training states.
2025-07-26 19:08:35,671 INFO: Validation ValSet,		 # psnr: 24.3122
2025-07-26 19:31:53,269 INFO: [Mamba..][epoch: 23, iter: 297,000, lr:(1.154e-06,)] [eta: 1:10:07, time (data): 1.388 (0.016)] l_pix: 1.5094e-02 
2025-07-26 19:55:11,281 INFO: [Mamba..][epoch: 23, iter: 298,000, lr:(1.068e-06,)] [eta: 0:46:44, time (data): 1.409 (0.018)] l_pix: 1.2445e-02 
2025-07-26 20:18:39,257 INFO: [Mamba..][epoch: 23, iter: 299,000, lr:(1.017e-06,)] [eta: 0:23:21, time (data): 1.411 (0.020)] l_pix: 1.5816e-02 
2025-07-26 20:42:09,276 INFO: [Mamba..][epoch: 23, iter: 300,000, lr:(1.000e-06,)] [eta: -1 day, 23:59:59, time (data): 1.406 (0.019)] l_pix: 1.3894e-02 
2025-07-26 20:42:09,277 INFO: Saving models and training states.
2025-07-26 20:42:22,297 INFO: Validation ValSet,		 # psnr: 24.2917
2025-07-26 20:42:22,314 INFO: End of training. Time consumed: 9:21:33
2025-07-26 20:42:22,314 INFO: Save the latest model.
2025-07-26 20:42:34,507 INFO: Validation ValSet,		 # psnr: 24.2893
